
# Threat Model (Abbreviated)

Adversary attempts to infer individual client samples from model updates.
Defenses: per-sample gradient clipping and Gaussian noise; additive mask secure aggregation (toy).
Out-of-scope: active poisoning, collusion attacks, traffic analysis, robust aggregation research.
